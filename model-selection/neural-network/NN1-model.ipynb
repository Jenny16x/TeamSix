{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd9ceea-a3ff-4606-8435-362181d4a36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>ERA</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Earned Runs</th>\n",
       "      <th>Strike Outs</th>\n",
       "      <th>Home Runs</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Outs Pitched</th>\n",
       "      <th>Batters Faced by Pitcher</th>\n",
       "      <th>Games Finished</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>League</th>\n",
       "      <th>Team</th>\n",
       "      <th>Games Started</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>AbbottJim</td>\n",
       "      <td>23</td>\n",
       "      <td>185000</td>\n",
       "      <td>4.51</td>\n",
       "      <td>246</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>635</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>75</td>\n",
       "      <td>AL</td>\n",
       "      <td>CAL</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>AbbottPaul</td>\n",
       "      <td>23</td>\n",
       "      <td>100000</td>\n",
       "      <td>5.97</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>75</td>\n",
       "      <td>AL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>AldredScott</td>\n",
       "      <td>22</td>\n",
       "      <td>100000</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>76</td>\n",
       "      <td>AL</td>\n",
       "      <td>DET</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>AndersonAllan</td>\n",
       "      <td>26</td>\n",
       "      <td>300000</td>\n",
       "      <td>4.53</td>\n",
       "      <td>214</td>\n",
       "      <td>95</td>\n",
       "      <td>82</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>566</td>\n",
       "      <td>797</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>71</td>\n",
       "      <td>AL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>AppierKevin</td>\n",
       "      <td>23</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.76</td>\n",
       "      <td>179</td>\n",
       "      <td>57</td>\n",
       "      <td>127</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>557</td>\n",
       "      <td>784</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>74</td>\n",
       "      <td>AL</td>\n",
       "      <td>KCA</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Full Name  Age  Salary   ERA  Hits  Earned Runs  Strike Outs  \\\n",
       "0  1990      AbbottJim   23  185000  4.51   246          106          105   \n",
       "1  1990     AbbottPaul   23  100000  5.97    37           23           25   \n",
       "2  1990    AldredScott   22  100000  3.77    13            6            7   \n",
       "3  1990  AndersonAllan   26  300000  4.53   214           95           82   \n",
       "4  1990    AppierKevin   23  100000  2.76   179           57          127   \n",
       "\n",
       "   Home Runs  Wins  Losses  Outs Pitched  Batters Faced by Pitcher  \\\n",
       "0         16    10      14           635                       925   \n",
       "1          0     0       5           104                       162   \n",
       "2          0     1       2            43                        63   \n",
       "3         20     7      18           566                       797   \n",
       "4         13    12       8           557                       784   \n",
       "\n",
       "   Games Finished  Weight  Height League Team  Games Started  \n",
       "0               0     200      75     AL  CAL             33  \n",
       "1               0     185      75     AL  MIN              7  \n",
       "2               0     195      76     AL  DET              3  \n",
       "3               0     178      71     AL  MIN             31  \n",
       "4               1     180      74     AL  KCA             24  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder, MinMaxScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import our input dataset\n",
    "df = pd.read_csv('../neural-network/resources/pitcher_salaries_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d757e83-084f-4d3b-aa21-0ea6fe861b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alyss\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>ERA</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Strike Outs</th>\n",
       "      <th>Outs Pitched</th>\n",
       "      <th>Batters Faced by Pitcher</th>\n",
       "      <th>Games Finished</th>\n",
       "      <th>Games Started</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185000</td>\n",
       "      <td>4.51</td>\n",
       "      <td>246</td>\n",
       "      <td>105</td>\n",
       "      <td>635</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000</td>\n",
       "      <td>5.97</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>104</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300000</td>\n",
       "      <td>4.53</td>\n",
       "      <td>214</td>\n",
       "      <td>82</td>\n",
       "      <td>566</td>\n",
       "      <td>797</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>2.76</td>\n",
       "      <td>179</td>\n",
       "      <td>127</td>\n",
       "      <td>557</td>\n",
       "      <td>784</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary   ERA  Hits  Strike Outs  Outs Pitched  Batters Faced by Pitcher  \\\n",
       "0  185000  4.51   246          105           635                       925   \n",
       "1  100000  5.97    37           25           104                       162   \n",
       "2  100000  3.77    13            7            43                        63   \n",
       "3  300000  4.53   214           82           566                       797   \n",
       "4  100000  2.76   179          127           557                       784   \n",
       "\n",
       "   Games Finished  Games Started  \n",
       "0               0             33  \n",
       "1               0              7  \n",
       "2               0              3  \n",
       "3               0             31  \n",
       "4               1             24  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop([\"Full Name\",\"Team\",\"League\",\"Age\",\"Earned Runs\",\"Home Runs\",\"Wins\",\"Losses\",\"Weight\",\"Height\",\"Year\"],1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f78146-a815-4e84-a1fa-d15f28d8da69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alyss\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"Salary\"].values\n",
    "X = df.drop([\"Salary\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf6d73c-5328-4c42-a64b-17d1fe9fd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9841111e-c4a0-43eb-a2be-b2b2919b9d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 21)                168       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 154       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330\n",
      "Trainable params: 330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 21\n",
    "hidden_nodes_layer2 = 7\n",
    "\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e53bbab-0efa-4d0b-abd8-036d2ff1b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37bad7e2-8a71-4f7d-bbb0-48a72379e1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 0s 643us/step - loss: 28584708145152.0000 - mse: 28584708145152.0000\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 28566695706624.0000 - mse: 28566695706624.0000\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 28514543730688.0000 - mse: 28514543730688.0000\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 28403640041472.0000 - mse: 28403640041472.0000\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 28213778579456.0000 - mse: 28213778579456.0000\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 27930277183488.0000 - mse: 27930277183488.0000\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 27548190769152.0000 - mse: 27548190769152.0000\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 27061322252288.0000 - mse: 27061322252288.0000\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 26471714258944.0000 - mse: 26471714258944.0000\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 0s 635us/step - loss: 25790825627648.0000 - mse: 25790825627648.0000\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 0s 696us/step - loss: 25037595738112.0000 - mse: 25037595738112.0000\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 24235288297472.0000 - mse: 24235288297472.0000\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 23405738852352.0000 - mse: 23405738852352.0000\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 22577640636416.0000 - mse: 22577640636416.0000\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 21782532718592.0000 - mse: 21782532718592.0000\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 0s 652us/step - loss: 21047036346368.0000 - mse: 21047036346368.0000\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 20393800761344.0000 - mse: 20393800761344.0000\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 0s 644us/step - loss: 19831453646848.0000 - mse: 19831453646848.0000\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 19367779631104.0000 - mse: 19367779631104.0000\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 19003418345472.0000 - mse: 19003418345472.0000\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18729838575616.0000 - mse: 18729838575616.0000\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18534216237056.0000 - mse: 18534216237056.0000\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 0s 675us/step - loss: 18401837711360.0000 - mse: 18401837711360.0000\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 0s 648us/step - loss: 18313178513408.0000 - mse: 18313178513408.0000\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18256681238528.0000 - mse: 18256681238528.0000\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 0s 624us/step - loss: 18222921285632.0000 - mse: 18222921285632.0000\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 0s 666us/step - loss: 18203719761920.0000 - mse: 18203719761920.0000\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 0s 643us/step - loss: 18190966980608.0000 - mse: 18190966980608.0000\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 0s 635us/step - loss: 18184268677120.0000 - mse: 18184268677120.0000\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 0s 644us/step - loss: 18179006922752.0000 - mse: 18179006922752.0000\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18178044329984.0000 - mse: 18178044329984.0000\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18175173328896.0000 - mse: 18175173328896.0000\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18173833248768.0000 - mse: 18173833248768.0000\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18171706736640.0000 - mse: 18171706736640.0000\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18170494582784.0000 - mse: 18170494582784.0000\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18171115339776.0000 - mse: 18171115339776.0000\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 0s 670us/step - loss: 18168686837760.0000 - mse: 18168686837760.0000\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18168930107392.0000 - mse: 18168930107392.0000\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18166648406016.0000 - mse: 18166648406016.0000\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 0s 643us/step - loss: 18165079736320.0000 - mse: 18165079736320.0000\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 0s 852us/step - loss: 18164255555584.0000 - mse: 18164255555584.0000\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18164379287552.0000 - mse: 18164379287552.0000\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18162498142208.0000 - mse: 18162498142208.0000\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18162015797248.0000 - mse: 18162015797248.0000\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18161095147520.0000 - mse: 18161095147520.0000\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18161197907968.0000 - mse: 18161197907968.0000\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18158951858176.0000 - mse: 18158951858176.0000\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18157934739456.0000 - mse: 18157934739456.0000\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18157609680896.0000 - mse: 18157609680896.0000\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18155831296000.0000 - mse: 18155831296000.0000\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18155101487104.0000 - mse: 18155101487104.0000\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18154734485504.0000 - mse: 18154734485504.0000\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18153312616448.0000 - mse: 18153312616448.0000\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18152391966720.0000 - mse: 18152391966720.0000\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18152066908160.0000 - mse: 18152066908160.0000\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18150689079296.0000 - mse: 18150689079296.0000\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18150653427712.0000 - mse: 18150653427712.0000\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18148252188672.0000 - mse: 18148252188672.0000\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18146926788608.0000 - mse: 18146926788608.0000\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18145903378432.0000 - mse: 18145903378432.0000\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18146853388288.0000 - mse: 18146853388288.0000\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18144175325184.0000 - mse: 18144175325184.0000\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18144947077120.0000 - mse: 18144947077120.0000\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18143646842880.0000 - mse: 18143646842880.0000\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18141895720960.0000 - mse: 18141895720960.0000\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18142113824768.0000 - mse: 18142113824768.0000\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18139412692992.0000 - mse: 18139412692992.0000\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18139211366400.0000 - mse: 18139211366400.0000\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18138590609408.0000 - mse: 18138590609408.0000\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18136881430528.0000 - mse: 18136881430528.0000\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18137531547648.0000 - mse: 18137531547648.0000\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18135671373824.0000 - mse: 18135671373824.0000\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18134308225024.0000 - mse: 18134308225024.0000\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 18134016720896.0000 - mse: 18134016720896.0000\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 0s 835us/step - loss: 18132326416384.0000 - mse: 18132326416384.0000\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18131019890688.0000 - mse: 18131019890688.0000\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18129933565952.0000 - mse: 18129933565952.0000\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18130027937792.0000 - mse: 18130027937792.0000\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18127924494336.0000 - mse: 18127924494336.0000\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18127632990208.0000 - mse: 18127632990208.0000\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - 0s 635us/step - loss: 18125953171456.0000 - mse: 18125953171456.0000\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 0s 652us/step - loss: 18125609238528.0000 - mse: 18125609238528.0000\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18124422250496.0000 - mse: 18124422250496.0000\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 0s 591us/step - loss: 18124185272320.0000 - mse: 18124185272320.0000\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18122534813696.0000 - mse: 18122534813696.0000\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18121563832320.0000 - mse: 18121563832320.0000\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18120888549376.0000 - mse: 18120888549376.0000\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 0s 591us/step - loss: 18121874210816.0000 - mse: 18121874210816.0000\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 0s 635us/step - loss: 18118795591680.0000 - mse: 18118795591680.0000\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18117751209984.0000 - mse: 18117751209984.0000\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18116893474816.0000 - mse: 18116893474816.0000\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18115222044672.0000 - mse: 18115222044672.0000\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18115198976000.0000 - mse: 18115198976000.0000\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18113410105344.0000 - mse: 18113410105344.0000\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 0s 669us/step - loss: 18114567733248.0000 - mse: 18114567733248.0000\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18111839338496.0000 - mse: 18111839338496.0000\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18111415713792.0000 - mse: 18111415713792.0000\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18111161958400.0000 - mse: 18111161958400.0000\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18108636987392.0000 - mse: 18108636987392.0000\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18108152545280.0000 - mse: 18108152545280.0000\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18107787640832.0000 - mse: 18107787640832.0000\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18106432880640.0000 - mse: 18106432880640.0000\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18104757256192.0000 - mse: 18104757256192.0000\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18104459460608.0000 - mse: 18104459460608.0000\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18104339922944.0000 - mse: 18104339922944.0000\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18102737698816.0000 - mse: 18102737698816.0000\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18101426978816.0000 - mse: 18101426978816.0000\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18100586020864.0000 - mse: 18100586020864.0000\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 0s 710us/step - loss: 18099178831872.0000 - mse: 18099178831872.0000\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18098161713152.0000 - mse: 18098161713152.0000\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 0s 591us/step - loss: 18098518228992.0000 - mse: 18098518228992.0000\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18096559489024.0000 - mse: 18096559489024.0000\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18095594799104.0000 - mse: 18095594799104.0000\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 0s 643us/step - loss: 18094999207936.0000 - mse: 18094999207936.0000\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18093296320512.0000 - mse: 18093296320512.0000\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 0s 630us/step - loss: 18092214190080.0000 - mse: 18092214190080.0000\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 0s 652us/step - loss: 18092147081216.0000 - mse: 18092147081216.0000\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 0s 730us/step - loss: 18090523885568.0000 - mse: 18090523885568.0000\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 0s 670us/step - loss: 18090232381440.0000 - mse: 18090232381440.0000\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18088141520896.0000 - mse: 18088141520896.0000\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18088808415232.0000 - mse: 18088808415232.0000\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 0s 678us/step - loss: 18086591725568.0000 - mse: 18086591725568.0000\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18086868549632.0000 - mse: 18086868549632.0000\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18086214238208.0000 - mse: 18086214238208.0000\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 0s 635us/step - loss: 18083768958976.0000 - mse: 18083768958976.0000\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18084316315648.0000 - mse: 18084316315648.0000\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 0s 620us/step - loss: 18082709897216.0000 - mse: 18082709897216.0000\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 0s 670us/step - loss: 18081600503808.0000 - mse: 18081600503808.0000\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 0s 591us/step - loss: 18080142983168.0000 - mse: 18080142983168.0000\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 0s 613us/step - loss: 18078203117568.0000 - mse: 18078203117568.0000\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 0s 800us/step - loss: 18078865817600.0000 - mse: 18078865817600.0000\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 0s 748us/step - loss: 18077695606784.0000 - mse: 18077695606784.0000\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 0s 670us/step - loss: 18077198581760.0000 - mse: 18077198581760.0000\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 0s 650us/step - loss: 18075162247168.0000 - mse: 18075162247168.0000\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 0s 730us/step - loss: 18074510032896.0000 - mse: 18074510032896.0000\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 0s 661us/step - loss: 18073270616064.0000 - mse: 18073270616064.0000\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18072626790400.0000 - mse: 18072626790400.0000\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 0s 652us/step - loss: 18071557242880.0000 - mse: 18071557242880.0000\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 0s 643us/step - loss: 18073289490432.0000 - mse: 18073289490432.0000\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 0s 652us/step - loss: 18070229745664.0000 - mse: 18070229745664.0000\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18068327628800.0000 - mse: 18068327628800.0000\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 0s 634us/step - loss: 18067864158208.0000 - mse: 18067864158208.0000\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18067341967360.0000 - mse: 18067341967360.0000\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18065404198912.0000 - mse: 18065404198912.0000\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 0s 626us/step - loss: 18065171415040.0000 - mse: 18065171415040.0000\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18064408051712.0000 - mse: 18064408051712.0000\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18063053291520.0000 - mse: 18063053291520.0000\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18061927120896.0000 - mse: 18061927120896.0000\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 0s 635us/step - loss: 18060702384128.0000 - mse: 18060702384128.0000\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18060004032512.0000 - mse: 18060004032512.0000\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 0s 624us/step - loss: 18060043878400.0000 - mse: 18060043878400.0000\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18058863181824.0000 - mse: 18058863181824.0000\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 0s 983us/step - loss: 18057258860544.0000 - mse: 18057258860544.0000\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 0s 739us/step - loss: 18056218673152.0000 - mse: 18056218673152.0000\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18055503544320.0000 - mse: 18055503544320.0000\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 0s 591us/step - loss: 18055906197504.0000 - mse: 18055906197504.0000\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18053347672064.0000 - mse: 18053347672064.0000\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18052519297024.0000 - mse: 18052519297024.0000\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18050935947264.0000 - mse: 18050935947264.0000\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - 0s 661us/step - loss: 18049973354496.0000 - mse: 18049973354496.0000\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18049268711424.0000 - mse: 18049268711424.0000\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 0s 600us/step - loss: 18048505348096.0000 - mse: 18048505348096.0000\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 0s 609us/step - loss: 18048855572480.0000 - mse: 18048855572480.0000\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 0s 817us/step - loss: 18046546608128.0000 - mse: 18046546608128.0000\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18044946481152.0000 - mse: 18044946481152.0000\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 0s 765us/step - loss: 18043751104512.0000 - mse: 18043751104512.0000\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 0s 661us/step - loss: 18043704967168.0000 - mse: 18043704967168.0000\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 0s 652us/step - loss: 18042597670912.0000 - mse: 18042597670912.0000\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 0s 713us/step - loss: 18041188384768.0000 - mse: 18041188384768.0000\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 0s 722us/step - loss: 18041909805056.0000 - mse: 18041909805056.0000\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 0s 635us/step - loss: 18039259004928.0000 - mse: 18039259004928.0000\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 0s 678us/step - loss: 18039879761920.0000 - mse: 18039879761920.0000\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18036698382336.0000 - mse: 18036698382336.0000\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 0s 704us/step - loss: 18036398489600.0000 - mse: 18036398489600.0000\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 0s 696us/step - loss: 18035903561728.0000 - mse: 18035903561728.0000\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 0s 652us/step - loss: 18034620104704.0000 - mse: 18034620104704.0000\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 0s 635us/step - loss: 18033842061312.0000 - mse: 18033842061312.0000\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18031312896000.0000 - mse: 18031312896000.0000\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 0s 696us/step - loss: 18032862691328.0000 - mse: 18032862691328.0000\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 0s 696us/step - loss: 18029903609856.0000 - mse: 18029903609856.0000\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 0s 687us/step - loss: 18028316065792.0000 - mse: 18028316065792.0000\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 0s 713us/step - loss: 18029314310144.0000 - mse: 18029314310144.0000\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 0s 652us/step - loss: 18028238471168.0000 - mse: 18028238471168.0000\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 0s 783us/step - loss: 18026474766336.0000 - mse: 18026474766336.0000\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 0s 704us/step - loss: 18025661071360.0000 - mse: 18025661071360.0000\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 0s 617us/step - loss: 18023763148800.0000 - mse: 18023763148800.0000\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 0s 643us/step - loss: 18022454525952.0000 - mse: 18022454525952.0000\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 0s 870us/step - loss: 18022152536064.0000 - mse: 18022152536064.0000\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 0s 791us/step - loss: 18020923604992.0000 - mse: 18020923604992.0000\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18021118640128.0000 - mse: 18021118640128.0000\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18021009588224.0000 - mse: 18021009588224.0000\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 18020623712256.0000 - mse: 18020623712256.0000\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18016846741504.0000 - mse: 18016846741504.0000\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18016249053184.0000 - mse: 18016249053184.0000\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18015651364864.0000 - mse: 18015651364864.0000\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18015420678144.0000 - mse: 18015420678144.0000\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18014971887616.0000 - mse: 18014971887616.0000\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18012719546368.0000 - mse: 18012719546368.0000\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18012105080832.0000 - mse: 18012105080832.0000\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 18011729690624.0000 - mse: 18011729690624.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "002448b4-46e4-4635-8634-db0bb5962864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 0s - loss: 23208478638080.0000 - mse: 23208478638080.0000 - 172ms/epoch - 4ms/step\n",
      "Loss: 23208478638080.0, MSE: 23208478638080.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, MSE: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "734daec1-4d65-4d3c-b2ba-1adb115e2dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc20lEQVR4nO3de3Cc9X3v8fd3JVmydbGMrIttWZZNwEBJbYMMtBQDJRMu04TDSdKGk2MCJWGYoQxMKUMKc1rO4Y8cQkLaDkk5brmekAQanMJpTiFM6xPDcIutythGGAy2sXyTfJdtfJH2e/7YR7Bar6SVvLvP7rOf14zGq2d/z+5Xj9af30+//T37mLsjIiLFLxZ2ASIikh0KdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiYhQA93MHjezXjNbl0HbJWbWaWYDZvbVpO1zzGy1mXWZ2XozuzW3VYuIFCYLcx26mS0BDgFPu/u5Y7RtB+qAvwBedPdfBNsnkfg5jplZDbAO+H13357T4kVECkyoI3R3XwnsTd5mZqeb2UvBqPtVMzsraLvZ3d8B4imPcdzdjwXfVqJpJBEpUYUYfsuA2939fBKj8R+PtYOZzTazd4CtwIManYtIKSoPu4BkwZTJ7wP/ZGZDmyvH2s/dtwK/a2YzgX82s1+4+67cVSoiUngKKtBJ/MWw390XTmRnd99uZuuBS4BfZLMwEZFCV1BTLu5+ENhkZl8DsIQFo+1jZq1mNjm4PQ24GNiQ82JFRApM2MsWfwa8Acw3sx4zuxn4BnCzma0B1gPXBm0Xm1kP8DXgfwUjcYCzgbeC9r8Bvu/ua/P9s4iIhC3UZYsiIpI9BTXlIiIiExfam6LTp0/39vb2sJ5eRKQorV69ere7N6a7L7RAb29vZ9WqVWE9vYhIUTKzLSPdpykXEZGIUKCLiESEAl1EJCIK7UxREZFxOXHiBD09PRw9ejTsUrKqqqqK1tZWKioqMt5HgS4iRa2np4fa2lra29tJ+gyooubu7Nmzh56eHubOnZvxfppyEZGidvToURoaGiIT5gBmRkNDw7j/6lCgi0jRi1KYD5nIz1R0gb5p92Ee/vUGVrzXy+FjA2GXIyJSMIpuDn3ttgM8smIjcYem2kr+x7W/w1Xnzgi7LBEpYTU1NRw6dCjsMopvhP7lBTNZe/+VPPWnFzC9ppJbf9LJ86t7wi5LRCR0RRfoANWV5Vx6ZiMv/NnFXDj3NP7bC+v4sC/83lFESpu7c/fdd3Puuefy+c9/nmeffRaAHTt2sGTJEhYuXMi5557Lq6++yuDgIDfeeOOnbX/4wx+e8vMX3ZRLsoqyGH/79UVc83ev8pfPr+W5W38v7JJEJET//f+s593tB7P6mOfMrOOvv/Q7GbVdvnw5XV1drFmzht27d7N48WKWLFnCT3/6U6688kruu+8+BgcHOXLkCF1dXWzbto1169YBsH///lOutShH6MlaplZx2+Wf4+3Ne1nbcyDsckSkhL322mtcf/31lJWV0dzczKWXXspvf/tbFi9ezBNPPMH999/P2rVrqa2tZd68eXz00UfcfvvtvPTSS9TV1Z3y8xf1CH3I1zpa+cGvN/DE65t4+I8Xhl2OiIQk05F0rox0waAlS5awcuVKfvWrX7F06VLuvvtubrjhBtasWcPLL7/Mj370I5577jkef/zxU3r+oh+hA9RVVfDV81v5lzU76Os/FnY5IlKilixZwrPPPsvg4CB9fX2sXLmSCy64gC1bttDU1MS3v/1tbr75Zjo7O9m9ezfxeJyvfOUrPPDAA3R2dp7y80dihA7wXy+aw9NvbOGl9TtZetGcsMsRkRJ03XXX8cYbb7BgwQLMjO9973u0tLTw1FNP8dBDD1FRUUFNTQ1PP/0027Zt46abbiIejwPw3e9+95Sff8xriprZbOBpoAWIA8vc/W9T2kwFfgK0kegkvu/uT4z2uB0dHZ7NC1y4O0seWsGZTbU8duPirD2uiBS27u5uzj777LDLyIl0P5uZrXb3jnTtM5lyGQDucvezgYuA28zsnJQ2twHvuvsC4DLgB2Y2abzFnwoz4/L5Tbz+4R6OnhjM51OLiBSEMQPd3Xe4e2dwux/oBmalNgNqLfHhAzXAXhIdQV5dPr+JT04M8vamvfl+ahGR0I3rTVEzawcWAW+l3PUIcDawHVgL3OHu8TT732Jmq8xsVV9f38QqHsVF8xqoLI+xYkNv1h9bRArXWFPHxWgiP1PGgW5mNcDzwJ3unrpy/0qgC5gJLAQeMbOTFlW6+zJ373D3jsbGtBetPiWTJ5Vx4bwGXv1gd9YfW0QKU1VVFXv27IlUqA99HnpVVdW49stolYuZVZAI82fcfXmaJjcB/9MTR3SjmW0CzgLeHlc1WdAxZxo//KCPg0dPUFeV+ZU+RKQ4tba20tPTQy7+6g/T0BWLxmPMQA/mxR8Dut394RGafQxcAbxqZs3AfOCjcVWSJQtn1+MO72w9wB+cMT2MEkQkjyoqKsZ1VZ8oy2SEfjGwFFhrZl3BtntJLFHE3R8FHgCeNLO1gAH3uHso8x4LZtcD0LV1nwJdRErKmIHu7q+RCOnR2mwHvpitok7F1MkVzGuspmurPtdFREpLJE79T7Vwdj1dW/dH6k0SEZGxRDLQF82uZ/ehY2zb/0nYpYiI5E0kA33h7GkArNG0i4iUkEgG+hnNNcQMNuzqD7sUEZG8iWSgV1WUMaehmg8U6CJSQiIZ6ABnNNXwvgJdREpIZAP9zOZaNu85wrEBffKiiJSGyAb6Gc01DMadTbsPh12KiEheRDbQz2yuBeD9XYdCrkREJD8iG+hzp1cTM/TGqIiUjMgGelVFGe0N1XpjVERKRmQDHRLz6B9oykVESkSkA31eYw1b9x1hYPCkiyeJiEROpAN9zmlTODHo7DhwNOxSRERyLtqB3lANwJY9R0KuREQk9yIe6FMA2LxHa9FFJPoiHegtdVVMKo/x8V6N0EUk+iId6LGY0XbaFDbrbFERKQGRDnSA9oYpGqGLSEmIfKC3nVbNlj1HdDk6EYm8yAd6+/QpfHJikL7+Y2GXIiKSU5EP9KGli5u1dFFEIi76gX5aYuniFi1dFJGIi3ygz6yfjBn07Psk7FJERHIq8oE+qTxGU20l2/Yr0EUk2iIf6ACz6iezXYEuIhFXGoE+bYpG6CISeSUR6DPrq9ix/yjxuNaii0h0jRnoZjbbzFaYWbeZrTezO0Zod5mZdQVtfpP9UieutX4yxwfj9B3SWnQRia7yDNoMAHe5e6eZ1QKrzewVd393qIGZ1QM/Bq5y94/NrCk35U7MrGmTgcRKl+a6qpCrERHJjTFH6O6+w907g9v9QDcwK6XZfwGWu/vHQbvebBd6KmbWJwJdb4yKSJSNaw7dzNqBRcBbKXedCUwzs/9nZqvN7IYs1ZcVs4JA1xujIhJlmUy5AGBmNcDzwJ3ufjDN45wPXAFMBt4wszfd/f2Ux7gFuAWgra3tVOoel9qqCuqqytmmk4tEJMIyGqGbWQWJMH/G3ZenadIDvOTuh919N7ASWJDayN2XuXuHu3c0NjaeSt3jpqWLIhJ1maxyMeAxoNvdHx6h2QvAJWZWbmZTgAtJzLUXjFn1VZpDF5FIy2TK5WJgKbDWzLqCbfcCbQDu/qi7d5vZS8A7QBz4R3dfl4N6J2xW/WTe+mhv2GWIiOTMmIHu7q8BlkG7h4CHslFULjRPraL/2ACHjw1QXZnxWwciIkWjJM4UhcQFowF2HjwaciUiIrlRcoG+64ACXUSiqWQCvXlqEOj9CnQRiaaSCfRPp1wO6PNcRCSaSibQqyvLqa0sZ5fm0EUkokom0CEx7bJTc+giElElFegtdVVa5SIikVVSgd5cV6UpFxGJrJIK9JaplfT2H2NQVy4SkQgqrUCvq2Iw7uzRlYtEJIJKKtCbdbaoiERYaQa6VrqISASVVKC3DJ0tqhG6iERQSQX69JpKymKmKRcRiaSSCvSymNFYU8mug3pTVESip6QCHRJni2rKRUSiqOQCvaWuUm+KikgklWCg6/R/EYmmkgv05qlV9B8d4MjxgbBLERHJqpIL9BatRReRiCrdQNe0i4hETMkFerNOLhKRiCq5QNel6EQkqkou0HUpOhGJqpILdNCl6EQkmkoz0Osq9aaoiEROiQZ6Fb0KdBGJmJIM9Ja6Knr7jxHXpehEJEJKMtCb66oYiDt7Dh8PuxQRkawZM9DNbLaZrTCzbjNbb2Z3jNJ2sZkNmtlXs1tmdjXXVQLQ269pFxGJjkxG6APAXe5+NnARcJuZnZPayMzKgAeBl7NbYvY1BWvRe/W56CISIWMGurvvcPfO4HY/0A3MStP0duB5oDerFeZAU21ihK616CISJeOaQzezdmAR8FbK9lnAdcCjY+x/i5mtMrNVfX194yw1exprh6ZcNEIXkejIONDNrIbECPxOdz+YcvffAPe4++Boj+Huy9y9w907Ghsbx11stlSWl3Fa9SSN0EUkUsozaWRmFSTC/Bl3X56mSQfwczMDmA5cY2YD7v7P2So025pqKzVCF5FIGTPQLZHSjwHd7v5wujbuPjep/ZPAvxRymEPijVGdXCQiUZLJCP1iYCmw1sy6gm33Am0A7j7qvHmhaqqt5P2d/WGXISKSNWMGuru/BlimD+juN55KQfnSXFdJ36HE2aKxWMY/nohIwSrJM0UhcbbooM4WFZEIKdlA11p0EYma0g304GzRPq10EZGIKNlAb67TtUVFJFpKNtAba3S2qIhES8kG+qTymM4WFZFIKdlAh8Qbo7v0iYsiEhGlHeh1VfTpM9FFJCJKOtCbNUIXkQgp6UBvCs4WHdS1RUUkAko60IfOFt2rs0VFJAJKOtB1tqiIRElpB7rOFhWRCCnpQNfZoiISJSUd6ENni2qli4hEQUkH+tDZor1aiy4iEVDSgQ46W1REokOBXlelEbqIRELJB3pzbSW9GqGLSASUfKDrbFERiYqSD3SdLSoiUVHygd5Uq7XoIhINCvS6oSsXKdBFpLiVfKAPnS2qN0ZFpNiVfKDrbFERiYqSD/RPry2qKRcRKXIlH+iQOFtUUy4iUuwU6OhsURGJhjED3cxmm9kKM+s2s/VmdkeaNt8ws3eCr9fNbEFuys0NnS0qIlFQnkGbAeAud+80s1pgtZm94u7vJrXZBFzq7vvM7GpgGXBhDurNiea6qk/PFi2LWdjliIhMyJgjdHff4e6dwe1+oBuYldLmdXffF3z7JtCa7UJzqamuksG4s+ewRukiUrzGNYduZu3AIuCtUZrdDPzrCPvfYmarzGxVX1/feJ46p4bOFtW0i4gUs4wD3cxqgOeBO9394AhtLicR6Peku9/dl7l7h7t3NDY2TqTenGjW2aIiEgGZzKFjZhUkwvwZd18+QpvfBf4RuNrd92SvxNxr+vTaohqhi0jxymSViwGPAd3u/vAIbdqA5cBSd38/uyXm3tDZoppyEZFilskI/WJgKbDWzLqCbfcCbQDu/ijwV0AD8ONE/jPg7h1ZrzZHJpXHaKiexE594qKIFLExA93dXwNGXcvn7t8CvpWtosLQMrWKnQc+CbsMEZEJ05migRlTq9hxQCN0ESleCvTAjKmTFegiUtQU6IGWqVUc+OQER44PhF2KiMiEKNADM+sTSxc1SheRYqVAD7TUTQZgpwJdRIqUAj2gEbqIFDsFemDo2qI79mvpoogUJwV6oKqijIbqSezQyUUiUqQU6ElaplZphC4iRUuBnkRr0UWkmCnQk+hsUREpZgr0JDPqdXKRiBQvBXqSmVMTa9G3ax5dRIqQAj1J67REoPfsU6CLSPFRoCdpnTYFUKCLSHFSoCdpqq2koswU6CJSlBToSWIxY1b9ZHr2HQm7FBGRcVOgp2idNkUjdBEpSgr0FK3TJivQRaQoKdBTtE6bzO5Dxzh6YjDsUkRExkWBnkIrXUSkWCnQU3y2Fl1vjIpIcVGgp9AIXUSKlQI9hdaii0ixUqCniMWM1mlT2LpXUy4iUlwU6GnMaZjCpt2Hwy5DRGRcFOhptDdUs3nPYdw97FJERDKmQE9jXmM1R44P0tt/LOxSREQypkBPo72hGkDTLiJSVMYMdDObbWYrzKzbzNab2R1p2piZ/Z2ZbTSzd8zsvNyUmx9zpycCfbMCXUSKSHkGbQaAu9y908xqgdVm9oq7v5vU5mrgjODrQuDvg3+L0sz6yUwqi2mELiJFZcwRurvvcPfO4HY/0A3MSml2LfC0J7wJ1JvZjKxXmydlMaNNK11EpMiMaw7dzNqBRcBbKXfNArYmfd/DyaGPmd1iZqvMbFVfX984S82voZUuIiLFIuNAN7Ma4HngTnc/mHp3ml1OWvPn7svcvcPdOxobG8dXaZ7Na6xm854jxONauigixSGjQDezChJh/oy7L0/TpAeYnfR9K7D91MsLT3tDNccH4mw/oI8AEJHikMkqFwMeA7rd/eERmr0I3BCsdrkIOODuO7JYZ959rqkGgA92HQq5EhGRzGSyyuViYCmw1sy6gm33Am0A7v4o8H+Ba4CNwBHgpqxXmmfzm2sBeG9nP5ef1RRyNSIiYxsz0N39NdLPkSe3ceC2bBVVCKZOqWDG1Co27Ex9u0BEpDDpTNFRnNVSy3s7+8MuQ0QkIwr0UcxvqePDvkOcGIyHXYqIyJgU6KM4q6WWE4OuE4xEpCgo0Ecxv+WzN0ZFRAqdAn0UpzfWUB4zvTEqIkVBgT6KSeUxTm+s4d3tCnQRKXwK9DEsnF1P19b9unqRiBQ8BfoYzptTz74jJ/TGqIgUPAX6GM6fMw2A1Vv2hVyJiMjoFOhjmDe9hrqqcjo/3h92KSIio1KgjyEWMxa1TaNTI3QRKXAK9AycP2ca7/f2c/DoibBLEREZkQI9Ax1zpuEOb3+0N+xSRERGpEDPQEf7aVRPKuPfN/SGXYqIyIgU6BmYVB5jyZmN/Ht3r9aji0jBUqBn6Iqzm9l58CjrddaoiBQoBXqGLpvfiBn8W7emXUSkMCnQMzS9ppJFs+v51drtmnYRkYKkQB+HP1k8m/d3HeLtTVrtIiKFR4E+Dl9eMIupkyt4+s0tYZciInISBfo4TJ5UxtfOb+XldTvZeeBo2OWIiAyjQB+nG36vHTN48KX3wi5FRGQYBfo4tTVM4dZLT+eX/7GN1zfuDrscEZFPKdAn4LbLP8echinc/Yt3NPUiIgVDgT4BVRVlPHL9eew/cpwbHn+L3n6FuoiET4E+QZ9vnco/3NDBlj1HuOpvXuWFrm0MDMbDLktESpiFdZJMR0eHr1q1KpTnzqYPdvXz58+tYe22AzTXVXLZmU0saqvnc001NNVWUV9dQW1lOWYWdqkiEgFmttrdO9Lep0A/dYNxZ8V7vTy7aitvb9rLgU+Gf256WcyYVBajLGbELPF9WSxGWQzKzIjFLLFt6Pan2xi2rSz22VfMkv9l2LZh+5R9tu9Q2+THi9nwxyyPDe0bPGbq48WSb5PYpyzNc59UD5/eTv0ZRmqb+pgiMnqgl2ew8+PAHwG97n5umvunAj8B2oLH+767P3FqJReXspjxhXOa+cI5zcTjztZ9R/ho92F29x9j/5ET7P/kOMcH4gzGIe7OQDy4HXcG3T/9dzDuxIN/h9oObRsYTLQ5PhBP2Sf94wx9xT35dqLzSW5bLJ9iYHZy5/ZZ55jawSV3TOk7x5M7KD7rZEfoHFMfJ/k50ndQjNJhpu8cy1LuH63DG7mjVedYqsYMdOBJ4BHg6RHuvw14192/ZGaNwAYze8bdj2epxqISixlzGqqZ01AddikZ8aHATw7+OGk6GB/WwQzG+azjSGl7cgfFZx3T0P0pHctn2xi+fzzYx1P2Serwhu+frjMjpfbE10A8zrGBxHMOjtbJJneeKXUVY+cIDAv88lhs1M4xufMcscM8qXO0YR1UeYZ/gSbfXz5G51iW8liJDjM2Yuf42f7DH2u0zjEW1Dhyh1lYneOYge7uK82sfbQmQK0lJolrgL3AQHbKk1yzYMokk55dRufDOhjSdAijd45pO6hROsf0He5Q55S+czzpr7vgr7+ROsd48uMkbRuIj9w5xlN+xuGDhfSd40mDgiLtHNNNoZan6Ryvv6CNb10yL+u1ZOP/8SPAi8B2oBb4E3dPu9zDzG4BbgFoa2vLwlOLFA51jtkzVuc4vKNixA7z5A6KYdsG4mN0jklth+4fSFsHo/w1m7xPosObXlOZk+OWjdfelUAX8IfA6cArZvaqu590JQh3XwYsg8Sboll4bhGJIHWOE5ONdeg3Acs9YSOwCTgrC48rIiLjkI1A/xi4AsDMmoH5wEdZeFwRERmHTJYt/gy4DJhuZj3AXwMVAO7+KPAA8KSZrQUMuMfd9alVIiJ5lskql+vHuH878MWsVSQiIhOiz3IREYkIBbqISEQo0EVEIkKBLiISEaF92qKZ9QFbJrDrdKAQV9GorvEr1NpU1/gUal1QuLWdSl1z3L0x3R2hBfpEmdmqkT46Mkyqa/wKtTbVNT6FWhcUbm25qktTLiIiEaFAFxGJiGIM9GVhFzAC1TV+hVqb6hqfQq0LCre2nNRVdHPoIiKSXjGO0EVEJA0FuohIRBRNoJvZVWa2wcw2mtl3Qq5ltpmtMLNuM1tvZncE2+83s21m1hV8XRNCbZvNbG3w/KuCbaeZ2Stm9kHw77Q81zQ/6Zh0mdlBM7szjONlZo+bWa+ZrUvaNuLxMbO/DF5zG8zsyhBqe8jM3jOzd8zsl2ZWH2xvN7NPko7do3mua8TfXb6O2Qh1PZtU02Yz6wq25/N4jZQPuX+duXvBfwFlwIfAPGASsAY4J8R6ZgDnBbdrgfeBc4D7gb8I+VhtBqanbPse8J3g9neAB0P+Xe4E5oRxvIAlwHnAurGOT/A7XQNUAnOD12BZnmv7IlAe3H4wqbb25HYhHLO0v7t8HrN0daXc/wPgr0I4XiPlQ85fZ8UyQr8A2OjuH7n7ceDnwLVhFePuO9y9M7jdD3QDs8KqJwPXAk8Ft58C/lN4pXAF8KG7T+Qs4VPm7itJXMg82UjH51rg5+5+zN03ARtJvBbzVpu7/9rdhy66/ibQmqvnH09do8jbMRutruCi9X8M/CwXzz2aUfIh56+zYgn0WcDWpO97KJAANbN2YBHwVrDpz4I/jx/P99RGwIFfm9nq4KLcAM3uvgMSLzagKYS6hnyd4f/Jwj5eMPLxKbTX3Z8C/5r0/Vwz+w8z+42ZXRJCPel+d4VyzC4Bdrn7B0nb8n68UvIh56+zYgl0S7Mt9PWWZlYDPA/c6YmLYv89iQtlLwR2kPiTL98udvfzgKuB28xsSQg1pGVmk4AvA/8UbCqE4zWagnndmdl9wADwTLBpB9Dm7ouAPwd+amZ1eSxppN9doRyz6xk+cMj78UqTDyM2TbNtQsesWAK9B5id9H0rsD2kWgAwswoSv6xn3H05gLvvcvdBd48D/0AO/zwfiSeuIIW79wK/DGrYZWYzgrpnAL35ritwNdDp7ruCGkM/XoGRjk9BvO7M7JvAHwHf8GDSNfjzfE9wezWJedcz81XTKL+70I+ZmZUD/xl4dmhbvo9XunwgD6+zYgn03wJnmNncYJT3deDFsIoJ5uceA7rd/eGk7TOSml0HrEvdN8d1VZtZ7dBtEm+orSNxrL4ZNPsm8EI+60oybNQU9vFKMtLxeRH4uplVmtlc4Azg7XwWZmZXAfcAX3b3I0nbG82sLLg9L6gtbxdnH+V3F/oxA74AvOfuPUMb8nm8RsoH8vE6y8e7vll65/gaEu8WfwjcF3Itf0DiT6J3gK7g6xrgfwNrg+0vAjPyXNc8Eu+WrwHWDx0noAH4N+CD4N/TQjhmU4A9wNSkbXk/XiQ6lB3ACRIjo5tHOz7AfcFrbgNwdQi1bSQxvzr0Ons0aPuV4He8BugEvpTnukb83eXrmKWrK9j+JHBrStt8Hq+R8iHnrzOd+i8iEhHFMuUiIiJjUKCLiESEAl1EJCIU6CIiEaFAFxGJCAW6iEhEKNBFRCLi/wPB2snloc9D7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66ee4cf9-08b1-4356-ae66-da4a42e05f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf073d-7d9c-4c68-b649-a61e3ce50617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
