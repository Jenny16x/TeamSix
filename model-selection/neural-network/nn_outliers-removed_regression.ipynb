{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd74c1ae-38ad-4a01-af16-97c7ffd6620f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>ERA</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Earned Runs</th>\n",
       "      <th>Strike Outs</th>\n",
       "      <th>Home Runs</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Outs Pitched</th>\n",
       "      <th>Batters Faced by Pitcher</th>\n",
       "      <th>Games Finished</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>League</th>\n",
       "      <th>Team</th>\n",
       "      <th>Games Started</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>AbbottJim</td>\n",
       "      <td>23</td>\n",
       "      <td>185000</td>\n",
       "      <td>4.51</td>\n",
       "      <td>246</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>635</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>75</td>\n",
       "      <td>AL</td>\n",
       "      <td>CAL</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>AbbottPaul</td>\n",
       "      <td>23</td>\n",
       "      <td>100000</td>\n",
       "      <td>5.97</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>75</td>\n",
       "      <td>AL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>AldredScott</td>\n",
       "      <td>22</td>\n",
       "      <td>100000</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>76</td>\n",
       "      <td>AL</td>\n",
       "      <td>DET</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>AndersonAllan</td>\n",
       "      <td>26</td>\n",
       "      <td>300000</td>\n",
       "      <td>4.53</td>\n",
       "      <td>214</td>\n",
       "      <td>95</td>\n",
       "      <td>82</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>566</td>\n",
       "      <td>797</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>71</td>\n",
       "      <td>AL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>AppierKevin</td>\n",
       "      <td>23</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.76</td>\n",
       "      <td>179</td>\n",
       "      <td>57</td>\n",
       "      <td>127</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>557</td>\n",
       "      <td>784</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>74</td>\n",
       "      <td>AL</td>\n",
       "      <td>KCA</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>2016</td>\n",
       "      <td>WoodAlex</td>\n",
       "      <td>25</td>\n",
       "      <td>530000</td>\n",
       "      <td>3.73</td>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>181</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>76</td>\n",
       "      <td>NL</td>\n",
       "      <td>LAN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>2016</td>\n",
       "      <td>WorleyVance</td>\n",
       "      <td>29</td>\n",
       "      <td>2600000</td>\n",
       "      <td>3.53</td>\n",
       "      <td>84</td>\n",
       "      <td>34</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>365</td>\n",
       "      <td>13</td>\n",
       "      <td>240</td>\n",
       "      <td>74</td>\n",
       "      <td>AL</td>\n",
       "      <td>BAL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>2016</td>\n",
       "      <td>WrightMike</td>\n",
       "      <td>26</td>\n",
       "      <td>510500</td>\n",
       "      <td>5.79</td>\n",
       "      <td>81</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>224</td>\n",
       "      <td>328</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>78</td>\n",
       "      <td>AL</td>\n",
       "      <td>BAL</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>2016</td>\n",
       "      <td>WrightSteven</td>\n",
       "      <td>32</td>\n",
       "      <td>514500</td>\n",
       "      <td>3.33</td>\n",
       "      <td>138</td>\n",
       "      <td>58</td>\n",
       "      <td>127</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>470</td>\n",
       "      <td>656</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>74</td>\n",
       "      <td>AL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>2016</td>\n",
       "      <td>YoungChris</td>\n",
       "      <td>37</td>\n",
       "      <td>4250000</td>\n",
       "      <td>6.19</td>\n",
       "      <td>104</td>\n",
       "      <td>61</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>406</td>\n",
       "      <td>7</td>\n",
       "      <td>255</td>\n",
       "      <td>82</td>\n",
       "      <td>AL</td>\n",
       "      <td>KCA</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4520 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year      Full Name  Age   Salary   ERA  Hits  Earned Runs  Strike Outs  \\\n",
       "0     1990      AbbottJim   23   185000  4.51   246          106          105   \n",
       "1     1990     AbbottPaul   23   100000  5.97    37           23           25   \n",
       "2     1990    AldredScott   22   100000  3.77    13            6            7   \n",
       "3     1990  AndersonAllan   26   300000  4.53   214           95           82   \n",
       "4     1990    AppierKevin   23   100000  2.76   179           57          127   \n",
       "...    ...            ...  ...      ...   ...   ...          ...          ...   \n",
       "4515  2016       WoodAlex   25   530000  3.73    56           25           66   \n",
       "4516  2016    WorleyVance   29  2600000  3.53    84           34           56   \n",
       "4517  2016     WrightMike   26   510500  5.79    81           48           50   \n",
       "4518  2016   WrightSteven   32   514500  3.33   138           58          127   \n",
       "4519  2016     YoungChris   37  4250000  6.19   104           61           94   \n",
       "\n",
       "      Home Runs  Wins  Losses  Outs Pitched  Batters Faced by Pitcher  \\\n",
       "0            16    10      14           635                       925   \n",
       "1             0     0       5           104                       162   \n",
       "2             0     1       2            43                        63   \n",
       "3            20     7      18           566                       797   \n",
       "4            13    12       8           557                       784   \n",
       "...         ...   ...     ...           ...                       ...   \n",
       "4515          5     1       4           181                       255   \n",
       "4516         11     2       2           260                       365   \n",
       "4517         12     3       4           224                       328   \n",
       "4518         12    13       6           470                       656   \n",
       "4519         28     3       9           266                       406   \n",
       "\n",
       "      Games Finished  Weight  Height League Team  Games Started  \n",
       "0                  0     200      75     AL  CAL             33  \n",
       "1                  0     185      75     AL  MIN              7  \n",
       "2                  0     195      76     AL  DET              3  \n",
       "3                  0     178      71     AL  MIN             31  \n",
       "4                  1     180      74     AL  KCA             24  \n",
       "...              ...     ...     ...    ...  ...            ...  \n",
       "4515               0     215      76     NL  LAN             10  \n",
       "4516              13     240      74     AL  BAL              4  \n",
       "4517               5     240      78     AL  BAL             12  \n",
       "4518               0     215      74     AL  BOS             24  \n",
       "4519               7     255      82     AL  KCA             13  \n",
       "\n",
       "[4520 rows x 19 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder, MinMaxScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import our input dataset\n",
    "df = pd.read_csv('./resources/outliers_removed.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e6c121-a256-4f39-93fe-aedbb0e64a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>ERA</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Earned Runs</th>\n",
       "      <th>Strike Outs</th>\n",
       "      <th>Home Runs</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Outs Pitched</th>\n",
       "      <th>Batters Faced by Pitcher</th>\n",
       "      <th>Games Finished</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>League</th>\n",
       "      <th>Team</th>\n",
       "      <th>Games Started</th>\n",
       "      <th>sal-log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>AbbottJim</td>\n",
       "      <td>23</td>\n",
       "      <td>185000</td>\n",
       "      <td>4.51</td>\n",
       "      <td>246</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>635</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>75</td>\n",
       "      <td>AL</td>\n",
       "      <td>CAL</td>\n",
       "      <td>33</td>\n",
       "      <td>5.267172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>AbbottPaul</td>\n",
       "      <td>23</td>\n",
       "      <td>100000</td>\n",
       "      <td>5.97</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>75</td>\n",
       "      <td>AL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>7</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>AldredScott</td>\n",
       "      <td>22</td>\n",
       "      <td>100000</td>\n",
       "      <td>3.77</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>76</td>\n",
       "      <td>AL</td>\n",
       "      <td>DET</td>\n",
       "      <td>3</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>AndersonAllan</td>\n",
       "      <td>26</td>\n",
       "      <td>300000</td>\n",
       "      <td>4.53</td>\n",
       "      <td>214</td>\n",
       "      <td>95</td>\n",
       "      <td>82</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>566</td>\n",
       "      <td>797</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>71</td>\n",
       "      <td>AL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>31</td>\n",
       "      <td>5.477121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>AppierKevin</td>\n",
       "      <td>23</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.76</td>\n",
       "      <td>179</td>\n",
       "      <td>57</td>\n",
       "      <td>127</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>557</td>\n",
       "      <td>784</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>74</td>\n",
       "      <td>AL</td>\n",
       "      <td>KCA</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>2016</td>\n",
       "      <td>WoodAlex</td>\n",
       "      <td>25</td>\n",
       "      <td>530000</td>\n",
       "      <td>3.73</td>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>181</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>76</td>\n",
       "      <td>NL</td>\n",
       "      <td>LAN</td>\n",
       "      <td>10</td>\n",
       "      <td>5.724276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>2016</td>\n",
       "      <td>WorleyVance</td>\n",
       "      <td>29</td>\n",
       "      <td>2600000</td>\n",
       "      <td>3.53</td>\n",
       "      <td>84</td>\n",
       "      <td>34</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>365</td>\n",
       "      <td>13</td>\n",
       "      <td>240</td>\n",
       "      <td>74</td>\n",
       "      <td>AL</td>\n",
       "      <td>BAL</td>\n",
       "      <td>4</td>\n",
       "      <td>6.414973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>2016</td>\n",
       "      <td>WrightMike</td>\n",
       "      <td>26</td>\n",
       "      <td>510500</td>\n",
       "      <td>5.79</td>\n",
       "      <td>81</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>224</td>\n",
       "      <td>328</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>78</td>\n",
       "      <td>AL</td>\n",
       "      <td>BAL</td>\n",
       "      <td>12</td>\n",
       "      <td>5.707996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>2016</td>\n",
       "      <td>WrightSteven</td>\n",
       "      <td>32</td>\n",
       "      <td>514500</td>\n",
       "      <td>3.33</td>\n",
       "      <td>138</td>\n",
       "      <td>58</td>\n",
       "      <td>127</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>470</td>\n",
       "      <td>656</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>74</td>\n",
       "      <td>AL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>24</td>\n",
       "      <td>5.711385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>2016</td>\n",
       "      <td>YoungChris</td>\n",
       "      <td>37</td>\n",
       "      <td>4250000</td>\n",
       "      <td>6.19</td>\n",
       "      <td>104</td>\n",
       "      <td>61</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>406</td>\n",
       "      <td>7</td>\n",
       "      <td>255</td>\n",
       "      <td>82</td>\n",
       "      <td>AL</td>\n",
       "      <td>KCA</td>\n",
       "      <td>13</td>\n",
       "      <td>6.628389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4520 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year      Full Name  Age   Salary   ERA  Hits  Earned Runs  Strike Outs  \\\n",
       "0     1990      AbbottJim   23   185000  4.51   246          106          105   \n",
       "1     1990     AbbottPaul   23   100000  5.97    37           23           25   \n",
       "2     1990    AldredScott   22   100000  3.77    13            6            7   \n",
       "3     1990  AndersonAllan   26   300000  4.53   214           95           82   \n",
       "4     1990    AppierKevin   23   100000  2.76   179           57          127   \n",
       "...    ...            ...  ...      ...   ...   ...          ...          ...   \n",
       "4515  2016       WoodAlex   25   530000  3.73    56           25           66   \n",
       "4516  2016    WorleyVance   29  2600000  3.53    84           34           56   \n",
       "4517  2016     WrightMike   26   510500  5.79    81           48           50   \n",
       "4518  2016   WrightSteven   32   514500  3.33   138           58          127   \n",
       "4519  2016     YoungChris   37  4250000  6.19   104           61           94   \n",
       "\n",
       "      Home Runs  Wins  Losses  Outs Pitched  Batters Faced by Pitcher  \\\n",
       "0            16    10      14           635                       925   \n",
       "1             0     0       5           104                       162   \n",
       "2             0     1       2            43                        63   \n",
       "3            20     7      18           566                       797   \n",
       "4            13    12       8           557                       784   \n",
       "...         ...   ...     ...           ...                       ...   \n",
       "4515          5     1       4           181                       255   \n",
       "4516         11     2       2           260                       365   \n",
       "4517         12     3       4           224                       328   \n",
       "4518         12    13       6           470                       656   \n",
       "4519         28     3       9           266                       406   \n",
       "\n",
       "      Games Finished  Weight  Height League Team  Games Started   sal-log  \n",
       "0                  0     200      75     AL  CAL             33  5.267172  \n",
       "1                  0     185      75     AL  MIN              7  5.000000  \n",
       "2                  0     195      76     AL  DET              3  5.000000  \n",
       "3                  0     178      71     AL  MIN             31  5.477121  \n",
       "4                  1     180      74     AL  KCA             24  5.000000  \n",
       "...              ...     ...     ...    ...  ...            ...       ...  \n",
       "4515               0     215      76     NL  LAN             10  5.724276  \n",
       "4516              13     240      74     AL  BAL              4  6.414973  \n",
       "4517               5     240      78     AL  BAL             12  5.707996  \n",
       "4518               0     215      74     AL  BOS             24  5.711385  \n",
       "4519               7     255      82     AL  KCA             13  6.628389  \n",
       "\n",
       "[4520 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create log transformed column for salary\n",
    "df['sal-log']=np.log10(df['Salary'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0d8866-0ac0-4650-ace0-a3195f3cc02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alyss\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERA</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Strike Outs</th>\n",
       "      <th>Outs Pitched</th>\n",
       "      <th>Batters Faced by Pitcher</th>\n",
       "      <th>Games Finished</th>\n",
       "      <th>Games Started</th>\n",
       "      <th>sal-log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.51</td>\n",
       "      <td>246</td>\n",
       "      <td>105</td>\n",
       "      <td>635</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5.267172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.97</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>104</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.77</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.53</td>\n",
       "      <td>214</td>\n",
       "      <td>82</td>\n",
       "      <td>566</td>\n",
       "      <td>797</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>5.477121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.76</td>\n",
       "      <td>179</td>\n",
       "      <td>127</td>\n",
       "      <td>557</td>\n",
       "      <td>784</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ERA  Hits  Strike Outs  Outs Pitched  Batters Faced by Pitcher  \\\n",
       "0  4.51   246          105           635                       925   \n",
       "1  5.97    37           25           104                       162   \n",
       "2  3.77    13            7            43                        63   \n",
       "3  4.53   214           82           566                       797   \n",
       "4  2.76   179          127           557                       784   \n",
       "\n",
       "   Games Finished  Games Started   sal-log  \n",
       "0               0             33  5.267172  \n",
       "1               0              7  5.000000  \n",
       "2               0              3  5.000000  \n",
       "3               0             31  5.477121  \n",
       "4               1             24  5.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop([\"Full Name\",\"Team\",\"League\",\"Age\",\"Earned Runs\",\"Home Runs\",\"Wins\",\"Losses\",\"Weight\",\"Height\",\"Year\",\"Salary\"],1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fca06b-2bb2-4786-a80b-74851d02b9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alyss\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"sal-log\"].values\n",
    "X = df.drop([\"sal-log\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e979053-b87d-468e-8d16-a4c37890a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee7057e-a67e-47cc-8d9a-a5ec527f8f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 21)                168       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 21)                462       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 7)                 154       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 792\n",
      "Trainable params: 792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 21\n",
    "hidden_nodes_layer2 = 21\n",
    "hidden_nodes_layer3 = 7\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff66bc9-ef9e-4d9b-a97e-4a4f8b2d6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64dff29f-525a-44b6-8bbf-5d513612d0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "106/106 [==============================] - 0s 684us/step - loss: 361.1417 - mse: 361.1417\n",
      "Epoch 2/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 5.4813 - mse: 5.4813\n",
      "Epoch 3/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 4.7604 - mse: 4.7604\n",
      "Epoch 4/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 4.2249 - mse: 4.2249\n",
      "Epoch 5/200\n",
      "106/106 [==============================] - 0s 638us/step - loss: 3.8145 - mse: 3.8145\n",
      "Epoch 6/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 3.4983 - mse: 3.4983\n",
      "Epoch 7/200\n",
      "106/106 [==============================] - 0s 698us/step - loss: 3.1485 - mse: 3.1485\n",
      "Epoch 8/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 2.8425 - mse: 2.8425\n",
      "Epoch 9/200\n",
      "106/106 [==============================] - 0s 770us/step - loss: 2.5896 - mse: 2.5896\n",
      "Epoch 10/200\n",
      "106/106 [==============================] - 0s 697us/step - loss: 2.3941 - mse: 2.3941\n",
      "Epoch 11/200\n",
      "106/106 [==============================] - 0s 685us/step - loss: 2.2320 - mse: 2.2320\n",
      "Epoch 12/200\n",
      "106/106 [==============================] - 0s 705us/step - loss: 1.7272 - mse: 1.7272\n",
      "Epoch 13/200\n",
      "106/106 [==============================] - 0s 733us/step - loss: 1.4342 - mse: 1.4342\n",
      "Epoch 14/200\n",
      "106/106 [==============================] - 0s 714us/step - loss: 1.0644 - mse: 1.0644\n",
      "Epoch 15/200\n",
      "106/106 [==============================] - 0s 715us/step - loss: 0.9115 - mse: 0.9115\n",
      "Epoch 16/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.8972 - mse: 0.8972\n",
      "Epoch 17/200\n",
      "106/106 [==============================] - 0s 629us/step - loss: 0.8508 - mse: 0.8508\n",
      "Epoch 18/200\n",
      "106/106 [==============================] - 0s 905us/step - loss: 0.7913 - mse: 0.7913\n",
      "Epoch 19/200\n",
      "106/106 [==============================] - 0s 800us/step - loss: 0.7538 - mse: 0.7538\n",
      "Epoch 20/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.7374 - mse: 0.7374\n",
      "Epoch 21/200\n",
      "106/106 [==============================] - 0s 666us/step - loss: 0.7752 - mse: 0.7752\n",
      "Epoch 22/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.7443 - mse: 0.7443\n",
      "Epoch 23/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.7396 - mse: 0.7396\n",
      "Epoch 24/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.6979 - mse: 0.6979\n",
      "Epoch 25/200\n",
      "106/106 [==============================] - 0s 658us/step - loss: 0.6632 - mse: 0.6632\n",
      "Epoch 26/200\n",
      "106/106 [==============================] - 0s 695us/step - loss: 0.6877 - mse: 0.6877\n",
      "Epoch 27/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.8027 - mse: 0.8027\n",
      "Epoch 28/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.8607 - mse: 0.8607\n",
      "Epoch 29/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.7179 - mse: 0.7179\n",
      "Epoch 30/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.8667 - mse: 0.8667\n",
      "Epoch 31/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.6395 - mse: 0.6395\n",
      "Epoch 32/200\n",
      "106/106 [==============================] - 0s 711us/step - loss: 0.6560 - mse: 0.6560\n",
      "Epoch 33/200\n",
      "106/106 [==============================] - 0s 715us/step - loss: 0.6220 - mse: 0.6220\n",
      "Epoch 34/200\n",
      "106/106 [==============================] - 0s 646us/step - loss: 0.6753 - mse: 0.6753\n",
      "Epoch 35/200\n",
      "106/106 [==============================] - 0s 661us/step - loss: 0.6624 - mse: 0.6624\n",
      "Epoch 36/200\n",
      "106/106 [==============================] - 0s 666us/step - loss: 0.5841 - mse: 0.5841\n",
      "Epoch 37/200\n",
      "106/106 [==============================] - 0s 699us/step - loss: 0.6802 - mse: 0.6802\n",
      "Epoch 38/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.7205 - mse: 0.7205\n",
      "Epoch 39/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.7312 - mse: 0.7312\n",
      "Epoch 40/200\n",
      "106/106 [==============================] - 0s 752us/step - loss: 0.6912 - mse: 0.6912\n",
      "Epoch 41/200\n",
      "106/106 [==============================] - 0s 743us/step - loss: 0.5439 - mse: 0.5439\n",
      "Epoch 42/200\n",
      "106/106 [==============================] - 0s 762us/step - loss: 0.5930 - mse: 0.5930\n",
      "Epoch 43/200\n",
      "106/106 [==============================] - 0s 695us/step - loss: 0.6365 - mse: 0.6365\n",
      "Epoch 44/200\n",
      "106/106 [==============================] - 0s 714us/step - loss: 0.5588 - mse: 0.5588\n",
      "Epoch 45/200\n",
      "106/106 [==============================] - 0s 724us/step - loss: 0.5381 - mse: 0.5381\n",
      "Epoch 46/200\n",
      "106/106 [==============================] - 0s 752us/step - loss: 0.5615 - mse: 0.5615\n",
      "Epoch 47/200\n",
      "106/106 [==============================] - 0s 638us/step - loss: 0.5246 - mse: 0.5246\n",
      "Epoch 48/200\n",
      "106/106 [==============================] - 0s 714us/step - loss: 0.6201 - mse: 0.6201\n",
      "Epoch 49/200\n",
      "106/106 [==============================] - 0s 762us/step - loss: 0.6722 - mse: 0.6722\n",
      "Epoch 50/200\n",
      "106/106 [==============================] - 0s 714us/step - loss: 0.5655 - mse: 0.5655\n",
      "Epoch 51/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.6303 - mse: 0.6303\n",
      "Epoch 52/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.5385 - mse: 0.5385\n",
      "Epoch 53/200\n",
      "106/106 [==============================] - 0s 638us/step - loss: 0.5166 - mse: 0.5166\n",
      "Epoch 54/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.5440 - mse: 0.5440\n",
      "Epoch 55/200\n",
      "106/106 [==============================] - 0s 724us/step - loss: 0.5788 - mse: 0.5788\n",
      "Epoch 56/200\n",
      "106/106 [==============================] - 0s 743us/step - loss: 0.7038 - mse: 0.7038\n",
      "Epoch 57/200\n",
      "106/106 [==============================] - 0s 733us/step - loss: 0.5588 - mse: 0.5588\n",
      "Epoch 58/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.6325 - mse: 0.6325\n",
      "Epoch 59/200\n",
      "106/106 [==============================] - 0s 724us/step - loss: 0.6158 - mse: 0.6158\n",
      "Epoch 60/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.4647 - mse: 0.4647\n",
      "Epoch 61/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.5960 - mse: 0.5960\n",
      "Epoch 62/200\n",
      "106/106 [==============================] - 0s 629us/step - loss: 0.5419 - mse: 0.5419\n",
      "Epoch 63/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.5408 - mse: 0.5408\n",
      "Epoch 64/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.4985 - mse: 0.4985\n",
      "Epoch 65/200\n",
      "106/106 [==============================] - 0s 743us/step - loss: 0.6270 - mse: 0.6270\n",
      "Epoch 66/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.5016 - mse: 0.5016\n",
      "Epoch 67/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.5132 - mse: 0.5132\n",
      "Epoch 68/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6007 - mse: 0.6007\n",
      "Epoch 69/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5567 - mse: 0.5567\n",
      "Epoch 70/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4942 - mse: 0.4942\n",
      "Epoch 71/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.5223 - mse: 0.5223\n",
      "Epoch 72/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4584\n",
      "Epoch 73/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4819 - mse: 0.4819\n",
      "Epoch 74/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4484 - mse: 0.4484\n",
      "Epoch 75/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4677 - mse: 0.4677\n",
      "Epoch 76/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.5071 - mse: 0.5071\n",
      "Epoch 77/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4388 - mse: 0.4388\n",
      "Epoch 78/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4659 - mse: 0.4659\n",
      "Epoch 79/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4304 - mse: 0.4304\n",
      "Epoch 80/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5335 - mse: 0.5335\n",
      "Epoch 81/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4206 - mse: 0.4206\n",
      "Epoch 82/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4465 - mse: 0.4465\n",
      "Epoch 83/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4566 - mse: 0.4566\n",
      "Epoch 84/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4434 - mse: 0.4434\n",
      "Epoch 85/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4439 - mse: 0.4439\n",
      "Epoch 86/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4744 - mse: 0.4744\n",
      "Epoch 87/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.5174 - mse: 0.5174\n",
      "Epoch 88/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4864 - mse: 0.4864\n",
      "Epoch 89/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4566 - mse: 0.4566\n",
      "Epoch 90/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.5096 - mse: 0.5096\n",
      "Epoch 91/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4826 - mse: 0.4826\n",
      "Epoch 92/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4776 - mse: 0.4776\n",
      "Epoch 93/200\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.4128 - mse: 0.4128\n",
      "Epoch 94/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4802 - mse: 0.4802\n",
      "Epoch 95/200\n",
      "106/106 [==============================] - 0s 790us/step - loss: 0.5527 - mse: 0.5527\n",
      "Epoch 96/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.4559 - mse: 0.4559\n",
      "Epoch 97/200\n",
      "106/106 [==============================] - 0s 724us/step - loss: 0.4563 - mse: 0.4563\n",
      "Epoch 98/200\n",
      "106/106 [==============================] - 0s 733us/step - loss: 0.3852 - mse: 0.3852\n",
      "Epoch 99/200\n",
      "106/106 [==============================] - 0s 714us/step - loss: 0.4007 - mse: 0.4007\n",
      "Epoch 100/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.3814 - mse: 0.3814\n",
      "Epoch 101/200\n",
      "106/106 [==============================] - 0s 771us/step - loss: 0.4744 - mse: 0.4744\n",
      "Epoch 102/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4828 - mse: 0.4828\n",
      "Epoch 103/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4284 - mse: 0.4284\n",
      "Epoch 104/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.4510 - mse: 0.4510\n",
      "Epoch 105/200\n",
      "106/106 [==============================] - 0s 695us/step - loss: 0.4409 - mse: 0.4409\n",
      "Epoch 106/200\n",
      "106/106 [==============================] - 0s 733us/step - loss: 0.4350 - mse: 0.4350\n",
      "Epoch 107/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.4446 - mse: 0.4446\n",
      "Epoch 108/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.3952 - mse: 0.3952\n",
      "Epoch 109/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.4077 - mse: 0.4077\n",
      "Epoch 110/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.4270 - mse: 0.4270\n",
      "Epoch 111/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.4145 - mse: 0.4145\n",
      "Epoch 112/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.3758 - mse: 0.3758\n",
      "Epoch 113/200\n",
      "106/106 [==============================] - 0s 838us/step - loss: 0.4525 - mse: 0.4525\n",
      "Epoch 114/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3792 - mse: 0.3792\n",
      "Epoch 115/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4615 - mse: 0.4615\n",
      "Epoch 116/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3907 - mse: 0.3907\n",
      "Epoch 117/200\n",
      "106/106 [==============================] - 0s 829us/step - loss: 0.5417 - mse: 0.5417\n",
      "Epoch 118/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.4547 - mse: 0.4547\n",
      "Epoch 119/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.4718 - mse: 0.4718\n",
      "Epoch 120/200\n",
      "106/106 [==============================] - 0s 781us/step - loss: 0.4096 - mse: 0.4096\n",
      "Epoch 121/200\n",
      "106/106 [==============================] - 0s 724us/step - loss: 0.3609 - mse: 0.3609\n",
      "Epoch 122/200\n",
      "106/106 [==============================] - 0s 819us/step - loss: 0.4821 - mse: 0.4821\n",
      "Epoch 123/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.4226 - mse: 0.4226\n",
      "Epoch 124/200\n",
      "106/106 [==============================] - 0s 638us/step - loss: 0.3699 - mse: 0.3699\n",
      "Epoch 125/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.3752 - mse: 0.3752\n",
      "Epoch 126/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.3833 - mse: 0.3833\n",
      "Epoch 127/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3622 - mse: 0.3622\n",
      "Epoch 128/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4231 - mse: 0.4231\n",
      "Epoch 129/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.5115 - mse: 0.5115\n",
      "Epoch 130/200\n",
      "106/106 [==============================] - 0s 733us/step - loss: 0.4471 - mse: 0.4471\n",
      "Epoch 131/200\n",
      "106/106 [==============================] - 0s 743us/step - loss: 0.3859 - mse: 0.3859\n",
      "Epoch 132/200\n",
      "106/106 [==============================] - 0s 762us/step - loss: 0.4714 - mse: 0.4714\n",
      "Epoch 133/200\n",
      "106/106 [==============================] - 0s 695us/step - loss: 0.3547 - mse: 0.3547\n",
      "Epoch 134/200\n",
      "106/106 [==============================] - 0s 695us/step - loss: 0.4605 - mse: 0.4605\n",
      "Epoch 135/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.6485 - mse: 0.6485\n",
      "Epoch 136/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.3992 - mse: 0.3992\n",
      "Epoch 137/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.3654 - mse: 0.3654\n",
      "Epoch 138/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.3603 - mse: 0.3603\n",
      "Epoch 139/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.3688 - mse: 0.3688\n",
      "Epoch 140/200\n",
      "106/106 [==============================] - 0s 695us/step - loss: 0.4394 - mse: 0.4394\n",
      "Epoch 141/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.4186 - mse: 0.4186\n",
      "Epoch 142/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.3999 - mse: 0.3999\n",
      "Epoch 143/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.4156 - mse: 0.4156\n",
      "Epoch 144/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.3687 - mse: 0.3687\n",
      "Epoch 145/200\n",
      "106/106 [==============================] - 0s 638us/step - loss: 0.3681 - mse: 0.3681\n",
      "Epoch 146/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.4989 - mse: 0.4989\n",
      "Epoch 147/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.4204 - mse: 0.4204\n",
      "Epoch 148/200\n",
      "106/106 [==============================] - 0s 699us/step - loss: 0.3489 - mse: 0.3489\n",
      "Epoch 149/200\n",
      "106/106 [==============================] - 0s 660us/step - loss: 0.3549 - mse: 0.3549\n",
      "Epoch 150/200\n",
      "106/106 [==============================] - 0s 638us/step - loss: 0.3750 - mse: 0.3750\n",
      "Epoch 151/200\n",
      "106/106 [==============================] - 0s 683us/step - loss: 0.3726 - mse: 0.3726\n",
      "Epoch 152/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.3586 - mse: 0.3586\n",
      "Epoch 153/200\n",
      "106/106 [==============================] - 0s 701us/step - loss: 0.3714 - mse: 0.3714\n",
      "Epoch 154/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.4682 - mse: 0.4682\n",
      "Epoch 155/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.3695 - mse: 0.3695\n",
      "Epoch 156/200\n",
      "106/106 [==============================] - 0s 695us/step - loss: 0.3701 - mse: 0.3701\n",
      "Epoch 157/200\n",
      "106/106 [==============================] - 0s 666us/step - loss: 0.3674 - mse: 0.3674\n",
      "Epoch 158/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.3553 - mse: 0.3553\n",
      "Epoch 159/200\n",
      "106/106 [==============================] - 0s 638us/step - loss: 0.3560 - mse: 0.3560\n",
      "Epoch 160/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.3395 - mse: 0.3395\n",
      "Epoch 161/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.4130 - mse: 0.4130\n",
      "Epoch 162/200\n",
      "106/106 [==============================] - 0s 743us/step - loss: 0.4108 - mse: 0.4108\n",
      "Epoch 163/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.3926 - mse: 0.3926\n",
      "Epoch 164/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.3790 - mse: 0.3790\n",
      "Epoch 165/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.3706 - mse: 0.3706\n",
      "Epoch 166/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.4528 - mse: 0.4528\n",
      "Epoch 167/200\n",
      "106/106 [==============================] - 0s 914us/step - loss: 0.3686 - mse: 0.3686\n",
      "Epoch 168/200\n",
      "106/106 [==============================] - 0s 781us/step - loss: 0.4127 - mse: 0.4127\n",
      "Epoch 169/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.4806 - mse: 0.4806\n",
      "Epoch 170/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.3471 - mse: 0.3471\n",
      "Epoch 171/200\n",
      "106/106 [==============================] - 0s 752us/step - loss: 0.4242 - mse: 0.4242\n",
      "Epoch 172/200\n",
      "106/106 [==============================] - 0s 714us/step - loss: 0.4241 - mse: 0.4241\n",
      "Epoch 173/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.3555 - mse: 0.3555\n",
      "Epoch 174/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.3877 - mse: 0.3877\n",
      "Epoch 175/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.3925 - mse: 0.3925\n",
      "Epoch 176/200\n",
      "106/106 [==============================] - 0s 638us/step - loss: 0.4655 - mse: 0.4655\n",
      "Epoch 177/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.3378 - mse: 0.3378\n",
      "Epoch 178/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.3422 - mse: 0.3422\n",
      "Epoch 179/200\n",
      "106/106 [==============================] - 0s 667us/step - loss: 0.4033 - mse: 0.4033\n",
      "Epoch 180/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.3796 - mse: 0.3796\n",
      "Epoch 181/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.3815 - mse: 0.3815\n",
      "Epoch 182/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.3887 - mse: 0.3887\n",
      "Epoch 183/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.3804 - mse: 0.3804\n",
      "Epoch 184/200\n",
      "106/106 [==============================] - 0s 638us/step - loss: 0.3902 - mse: 0.3902\n",
      "Epoch 185/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.3744 - mse: 0.3744\n",
      "Epoch 186/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.3885 - mse: 0.3885\n",
      "Epoch 187/200\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3846 - mse: 0.3846\n",
      "Epoch 188/200\n",
      "106/106 [==============================] - 0s 724us/step - loss: 0.3459 - mse: 0.3459\n",
      "Epoch 189/200\n",
      "106/106 [==============================] - 0s 714us/step - loss: 0.4197 - mse: 0.4197\n",
      "Epoch 190/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.3634 - mse: 0.3634\n",
      "Epoch 191/200\n",
      "106/106 [==============================] - 0s 679us/step - loss: 0.3576 - mse: 0.3576\n",
      "Epoch 192/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.3493 - mse: 0.3493\n",
      "Epoch 193/200\n",
      "106/106 [==============================] - 0s 695us/step - loss: 0.3595 - mse: 0.3595\n",
      "Epoch 194/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.3462 - mse: 0.3462\n",
      "Epoch 195/200\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.3572 - mse: 0.3572\n",
      "Epoch 196/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.4337 - mse: 0.4337\n",
      "Epoch 197/200\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.4272 - mse: 0.4272\n",
      "Epoch 198/200\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.3752 - mse: 0.3752\n",
      "Epoch 199/200\n",
      "106/106 [==============================] - 0s 686us/step - loss: 0.4258 - mse: 0.4258\n",
      "Epoch 200/200\n",
      "106/106 [==============================] - 0s 752us/step - loss: 0.3745 - mse: 0.3745\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2279fb30-37e7-44e8-b1e8-62eeb932c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 0s - loss: 3.2440 - mse: 3.2440 - 79ms/epoch - 2ms/step\n",
      "Loss: 3.243964910507202, MSE: 3.243964910507202\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, MSE: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06a64fd9-ec3d-4561-ab9a-9f14138049ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e74a5cfd-77fb-437c-bdc6-2eed3844cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4354dd00-da49-4e78-b4e1-50cf061b19da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
